{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset, net, utils, loss\n",
    "\n",
    "import torch, random, torchvision, importlib\n",
    "from PIL import ImageDraw\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_printoptions(linewidth=240, threshold=10000, sci_mode=False, precision=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dataset)\n",
    "importlib.reload(utils)\n",
    "\n",
    "cv = utils.Converter()\n",
    "rd = dataset.RisikoDataset(dataset_dir='Datasets/Generated_Dataset/train', cv=cv, is_trainset=True)\n",
    "#rd = dataset.RisikoDataset(dataset_dir='Datasets/Professor_Material/real_images/', cv=cv, is_trainset=True, labels_extension='.txt')\n",
    "\n",
    "#print(rd.loss_labels[0][rd.loss_labels[0][...,0]==1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find mean and std of full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_mean, cumulative_std = torch.zeros(3, dtype=torch.float32), torch.zeros(3, dtype=torch.float32)\n",
    "pbar = tqdm(total=len(rd), unit='images')\n",
    "\n",
    "for i in range(len(rd)):\n",
    "    img = rd.images[i].type(torch.float32)\n",
    "    torch.add(cumulative_mean, torch.mean(img, dim=(1,2)), out=cumulative_mean)\n",
    "    torch.add(cumulative_std, torch.std(img, dim=(1,2)), out=cumulative_std)\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "torch.divide(cumulative_mean, len(rd), out=cumulative_mean)\n",
    "torch.divide(cumulative_std, len(rd), out=cumulative_std)\n",
    "\n",
    "print('mean = ' + str(cumulative_mean))\n",
    "print('std  = ' + str(cumulative_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv.grids_shape)\n",
    "print(cv.grids_relative_area_sqrt)\n",
    "print(cv.netout_grid_limits)\n",
    "print(cv.netout_abox_multiplier[-1], cv.netout_abox_offset[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Dataset and Conversion of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_max = torch.zeros((4,), dtype=cv.netout_dtype)\n",
    "lbl_min = torch.full((4,), 10e30, dtype=cv.netout_dtype)\n",
    "for lbl in rd.loss_labels:\n",
    "    lbl = lbl[lbl[:,0] == 1][:,(3,4,6,7)]\n",
    "    \n",
    "    if lbl.shape[0] > 0:\n",
    "        lbl_curr_max = lbl.max(dim=0)[0]\n",
    "        lbl_curr_min = lbl.min(dim=0)[0]\n",
    "\n",
    "        #print('current: max', lbl_curr_max, '\\t min', lbl_curr_min)\n",
    "\n",
    "        torch.maximum(lbl_max, lbl_curr_max, out=lbl_max)\n",
    "        torch.minimum(lbl_min, lbl_curr_min, out=lbl_min)\n",
    "\n",
    "print('MAX =', lbl_max)\n",
    "print('MIN =', lbl_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(rd.loss_labels[i][rd.loss_labels[i][:,0] == 1][:, 5])\n",
    "print(torch.arange(rd.loss_labels[i].shape[0])[rd.loss_labels[i][:,0] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ( \"blue\", \"red\", \"yellow\", \"purple\", \"black\", \"green\")\n",
    "\n",
    "rd.salt_pepper_hval = 150\n",
    "\n",
    "rnd_idx = random.randint(a=0, b=rd.__len__()-1)\n",
    "# rnd_idx = 37\n",
    "print('Chosen image idx: ' + str(rnd_idx))\n",
    "img_tensor, loss_labels = rd[rnd_idx]\n",
    "# print(img_tensor)\n",
    "img_tensor = rd.invnorm(img_tensor).type(torch.uint8)\n",
    "# print(img_tensor)\n",
    "\n",
    "labels = rd.cv.convert_losslabels_to_labels(loss_labels)\n",
    "labels_origin = rd.labels[rnd_idx].clone()\n",
    "rd.cv.convert_labels_from_relative_to_absolute_values(labels)\n",
    "rd.cv.convert_labels_from_relative_to_absolute_values(labels_origin)\n",
    "boxes = rd.cv.convert_boxes_cxcywh_to_x1y1x2y2(labels[:,1:])\n",
    "print(boxes)\n",
    "\n",
    "print('Number of objects: ' + str(boxes.shape[0]))\n",
    "\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "img = to_pil(img_tensor)\n",
    "\n",
    "if (boxes.shape[0] != 0):\n",
    "\n",
    "    if len(boxes.shape) == 1:\n",
    "        boxes = boxes.unsqueeze(1)\n",
    "\n",
    "    img_draw = ImageDraw.Draw(img)\n",
    "\n",
    "    for i in range(boxes.shape[0]):\n",
    "\n",
    "        x0, y0, x1, y1 = boxes[i]\n",
    "        \n",
    "        img_draw.point(labels[i,1:3].tolist(), fill='red')\n",
    "        img_draw.rectangle((x0, y0, x1, y1), outline=colors[int(labels[i,0]%6)])\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rd))\n",
    "print(rd.loss_labels[0][rd.loss_labels[0][:,0] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network forward test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(net)\n",
    "\n",
    "my_net = net.GridNet(abox_count=cv.abox_count)\n",
    "\n",
    "rnd_idx = random.randint(a=0, b=rd.__len__()-1)\n",
    "# rnd_idx = 313\n",
    "print('Chosen index = ' + str(rnd_idx))\n",
    "img_tensor, netout_labels = rd[rnd_idx]\n",
    "print(netout_labels.shape)\n",
    "img_tensor = img_tensor.type(cv.netout_dtype).unsqueeze(0)\n",
    "\n",
    "my_net.train()\n",
    "netout = my_net.forward(img_tensor)\n",
    "print('Train shape: ' + str(netout.shape))\n",
    "my_net.eval()\n",
    "netout = my_net.forward(img_tensor)\n",
    "print('Eval shape: ' + str(netout.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "print(summary(my_net, input_size=(1,3,512,512)))\n",
    "print(my_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(loss)\n",
    "\n",
    "my_loss = loss.RisikoLoss(\n",
    "    lambda_abox=0.1,\n",
    "    lambda_coord=1,\n",
    "    lambda_no_obj=0.05,\n",
    "    lambda_class_obj=1,\n",
    "    lambda_class_color=0.1,\n",
    "    abox_count=cv.abox_count\n",
    ")\n",
    "\n",
    "artificial_labels = torch.zeros(size=(3,10,8), dtype=cv.netout_dtype)\n",
    "artificial_labels[0,1] = torch.tensor((1,1,2,0.1,0.1,0,0.3,-0.2))\n",
    "artificial_labels[0,2] = torch.tensor((1,1,5,0.1,0.1,1,0.3,-0.2))\n",
    "artificial_labels[1,0] = torch.tensor((1,1,3,0.1,0.1,0,0.3,-0.2))\n",
    "\n",
    "artificial_netout = torch.zeros(size=(3,10,19), dtype=cv.netout_dtype)\n",
    "artificial_netout[0,1] = torch.tensor((1,1,0,0,10,0,0,0,0.1,0.1,10,0,0,0.3,-0.2,0,0,0,0))\n",
    "artificial_netout[0,2] = torch.tensor((1,1,0,0,0,0,0,10,0.1,0.1,0,10,0,0,0,0.3,-0.2,0,0))\n",
    "artificial_netout[1,0] = torch.tensor((1,1,0,0,0,10,0,0,0.1,0.1,10,0,0,0.3,-0.2,0,0,0,0))\n",
    "\n",
    "print(my_loss(artificial_netout, artificial_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

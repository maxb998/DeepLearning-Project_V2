{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risiko Detection: Boxes Analisys #\n",
    "Here we will analyze the properties of the bounding boxes specified as text files inside the directory specified as *labels_path*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "plt.rcParams['figure.figsize'] = [9, 9]\n",
    "\n",
    "labels_path = \"Professor_Material/real_images/labels\"\n",
    "images_path = \"Professor_Material/real_images/images\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data ####\n",
    "Read labels files, compute areas and ratios and do some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_files = sorted( filter( lambda x: os.path.isfile(os.path.join(labels_path, x)),os.listdir(labels_path) ) )\n",
    "boxes = np.empty([0,4], dtype=np.float32)\n",
    "\n",
    "labels_list = []\n",
    "img_dims = []\n",
    "for filename in labels_files:\n",
    "    lbl = np.loadtxt(os.path.join(labels_path, filename), dtype=np.float32)\n",
    "\n",
    "    img_path = os.path.join(images_path, os.path.splitext(filename)[0] + \".jpg\")\n",
    "    img = cv2.imread(img_path)\n",
    "    img_dim = np.array([img.shape[0], img.shape[1], img.shape[0], img.shape[1]], dtype=np.float32)\n",
    "    #img_dim = np.array([1920,1080,1920,1080], dtype=np.float32)\n",
    "\n",
    "    np.multiply(lbl[:,1:], img_dim, out=lbl[:,1:])\n",
    "    np.floor(lbl, out=lbl)\n",
    "\n",
    "    img_dims.append(img_dim)\n",
    "    labels_list.append(lbl)\n",
    "    boxes = np.vstack([boxes, lbl[:,1:]], dtype=np.float32)\n",
    "\n",
    "sizes = boxes[:,2:]\n",
    "areas = np.sqrt(sizes[:,0] * sizes[:,1])\n",
    "ratios = sizes[:,0] / sizes[:,1]\n",
    "\n",
    "box_stat_data = np.hstack([sizes, areas.reshape([areas.shape[0],1]), ratios.reshape([ratios.shape[0],1])])\n",
    "\n",
    "df = pd.DataFrame(box_stat_data)\n",
    "df.columns = [\"Width\", \"Height\", \"Area\", \"Ratio\"]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Image with objects that have the smallest area to inspect it manually (check whether it's actually worth it to allow detection for such small objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dims = np.array([0, 1000, 1000, 1000], np.float32)\n",
    "for i in range(len(labels_list)):\n",
    "    inst_areas = labels_list[i][:,3] * labels_list[i][:,4]\n",
    "    min_id = np.argmin(inst_areas)\n",
    "    if inst_areas[min_id] < min_dims[1]:\n",
    "        min_dims[0:] = i, inst_areas[min_id], labels_list[i][min_id,3] , labels_list[i][min_id,4]\n",
    "\n",
    "print(min_dims) \n",
    "print(labels_files[int(min_dims[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check some statistics about the IoU in each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(boxes:np.ndarray) -> float:\n",
    "\n",
    "    half_dims = boxes[:, 2:] / 2\n",
    "    x1 = boxes[:, 0] - half_dims[:, 0]\n",
    "    x2 = boxes[:, 0] + half_dims[:, 0]\n",
    "    y1 = boxes[:, 1] - half_dims[:, 1]\n",
    "    y2 = boxes[:, 1] + half_dims[:, 1]\n",
    "\n",
    "    xA = np.maximum(x1, np.expand_dims(x1, 1))\n",
    "    yA = np.maximum(y1, np.expand_dims(y1, 1))\n",
    "    xB = np.minimum(x2, np.expand_dims(x2, 1))\n",
    "    yB = np.minimum(y2, np.expand_dims(y2, 1))\n",
    "\n",
    "    interArea = np.maximum((xB - xA), 0) * np.maximum((yB - yA), 0)\n",
    "\n",
    "    boxesArea = (x2 - x1) * (y2 - y1)\n",
    "    unionArea = boxesArea + np.expand_dims(boxesArea,1) - interArea\n",
    "\n",
    "    IoU = interArea / unionArea\n",
    "\n",
    "    IoU = IoU[~np.eye(IoU.shape[0],dtype=bool)].reshape(IoU.shape[0],-1)\n",
    "\n",
    "    IoU = IoU.flatten()\n",
    "\n",
    "    return np.max(IoU)\n",
    "\n",
    "max_img_iou_list = np.empty([0], dtype=np.float32)\n",
    "for boxes in labels_list:\n",
    "    max_img_iou_list = np.hstack([max_img_iou_list, IoU(boxes[:,1:])])\n",
    "df = pd.DataFrame(max_img_iou_list)\n",
    "df.columns= [\"Max IoU each img\"]\n",
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot all points ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sizes[:,0], sizes[:,1], s=5, marker='.')\n",
    "plt.xlim([0,sizes[:,0].max()+20])\n",
    "plt.ylim([0,sizes[:,1].max()+20])\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.minorticks_on()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get histogram on areas to estimate size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "plt.hist(areas, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.hist(sizes[:,0], bins=100)\n",
    "ax2.hist(sizes[:,1], bins=100)\n",
    "plt.rcParams['figure.figsize'] = [9, 9]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans Clustering ##\n",
    "Now we run some clustering to identify patterns in the data. This will useful when generating the neural network model and detecting the tanks and flags.\n",
    "In particular this results will be useful when chosing the anchor boxes size and ratios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering plot function ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(points:np.ndarray, labels:np.ndarray, k:int, centers=None):\n",
    "    # plot the 3 clusters\n",
    "    colors = [\"green\", \"darkorange\", \"purple\", \"blue\", \"lightblue\", \"lightgreen\"]\n",
    "    for i in range(k):\n",
    "        plt.scatter(points[labels == i, 0], points[labels == i, 1], s=5, c=colors[i], marker='.', label=\"cluster \" + str(i))\n",
    "\n",
    "    # plot the centroids\n",
    "    if not (centers is None):\n",
    "        plt.scatter(centers[:, 0], centers[:, 1], s=20, marker='o', c='red', edgecolor='black', label='centroids')\n",
    "\n",
    "    plt.legend(scatterpoints=1)\n",
    "    plt.minorticks_on()\n",
    "    plt.xlim([0,points[:,0].max()+20])\n",
    "    plt.ylim([0,points[:,1].max()+20])\n",
    "    plt.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "    plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering on Size ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_sizes = 3\n",
    "km_size = KMeans(n_clusters=k_sizes, n_init='auto')\n",
    "km_sizes_output = km_size.fit_predict(sizes)\n",
    "print(km_size.cluster_centers_.round())\n",
    "\n",
    "plot_clusters(sizes, km_sizes_output, k_sizes, km_size.cluster_centers_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering on Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_ratios = 3\n",
    "km_ratios = KMeans(n_clusters=k_ratios, n_init='auto')\n",
    "km_ratios_output = km_ratios.fit_predict(ratios.reshape(ratios.shape[0], 1))\n",
    "print(km_size.cluster_centers_)\n",
    "\n",
    "plot_clusters(sizes, km_ratios_output, k_ratios)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some combination of the both clusterings ####\n",
    "First we separtate the sets into the clusters identified by size clustering, then we run clustering on ratios on each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_subsets, ratios_subsets = [], []\n",
    "for i in range(k_sizes):\n",
    "    sizes_subsets.append(sizes[km_sizes_output == i])\n",
    "    ratios_subsets.append(ratios[km_sizes_output == i])\n",
    "\n",
    "k_ratios = 3\n",
    "km_ratios = KMeans(n_clusters=k_ratios, n_init='auto')\n",
    "for i in range(k_sizes):\n",
    "    km_ratios_output = km_ratios.fit_predict(ratios_subsets[i].reshape(ratios_subsets[i].shape[0], 1))\n",
    "\n",
    "    \n",
    "\n",
    "    plot_clusters(sizes_subsets[i], km_ratios_output, k_ratios)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(km_ratios_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

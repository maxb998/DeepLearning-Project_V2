{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset, utils, net, loss\n",
    "\n",
    "import torch, random, torchvision, importlib\n",
    "from PIL import ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "torch.set_printoptions(linewidth=240, threshold=10000, sci_mode=False, precision=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dataset)\n",
    "importlib.reload(utils)\n",
    "\n",
    "cv = utils.Converter()\n",
    "rd = dataset.RisikoDataset(dataset_dir='Datasets/Generated_Dataset/val', cv=cv, train_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Dataset and Conversion of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ( \"blue\", \"red\", \"yellow\", \"purple\", \"black\", \"green\")\n",
    "\n",
    "rnd_idx = random.randint(a=0, b=rd.__len__()-1)\n",
    "# rnd_idx = 326\n",
    "img_tensor, netout_labels = rd[rnd_idx]\n",
    "\n",
    "boxes = rd.cv.convert_labels_to_basic_labels(netout_labels)\n",
    "# rd.cv.convert_labels_from_relative_to_absolute_values(boxes, use_netin_shape=True)\n",
    "\n",
    "print(netout_labels[netout_labels[...,0] == 1])\n",
    "print(boxes)\n",
    "\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "img = to_pil(img_tensor)\n",
    "\n",
    "if (boxes.shape[0] != 0):\n",
    "\n",
    "    if len(boxes.shape) == 1:\n",
    "        boxes = boxes.unsqueeze(1)\n",
    "\n",
    "    box_coords = boxes[:, 2:]\n",
    "    torch.multiply(box_coords, torch.tensor([img.width, img.height, img.width, img.height], dtype=torch.float32), out=box_coords)\n",
    "    print(box_coords)\n",
    "\n",
    "    img_draw = ImageDraw.Draw(img)\n",
    "\n",
    "    for i in range(box_coords.shape[0]):\n",
    "\n",
    "        x0 = int(box_coords[i,0] - box_coords[i,2] / 2)\n",
    "        x1 = int(box_coords[i,0] + box_coords[i,2] / 2)\n",
    "        y0 = int(box_coords[i,1] - box_coords[i,3] / 2)\n",
    "        y1 = int(box_coords[i,1] + box_coords[i,3] / 2)\n",
    "\n",
    "        img_draw.rectangle([x0, y0, x1, y1], outline=colors[int(boxes[i,1])%6])\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network forward test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(net)\n",
    "\n",
    "my_net = net.DetektorNet(abox_count=cv.abox_count)\n",
    "\n",
    "rnd_idx = random.randint(a=0, b=rd.__len__()-1)\n",
    "# rnd_idx = 313\n",
    "print('Chosen index = ' + str(rnd_idx))\n",
    "img_tensor, netout_labels = rd[rnd_idx]\n",
    "print(netout_labels.shape)\n",
    "img_tensor = img_tensor.type(cv.netout_dtype).unsqueeze(0)\n",
    "\n",
    "my_net.train()\n",
    "netout = my_net.forward(img_tensor)\n",
    "print('Train shape: ' + str(netout.shape))\n",
    "my_net.eval()\n",
    "netout = my_net.forward(img_tensor)\n",
    "print('Eval shape: ' + str(netout.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(loss)\n",
    "\n",
    "my_loss = loss.RisikoLoss(\n",
    "    lambda_abox=0.1,\n",
    "    lambda_coord=1,\n",
    "    lambda_no_obj=0.05,\n",
    "    lambda_class_obj=1,\n",
    "    lambda_class_color=0.1,\n",
    "    abox_count=cv.abox_count\n",
    ")\n",
    "\n",
    "artificial_labels = torch.zeros(size=(3,10,8), dtype=cv.netout_dtype)\n",
    "artificial_labels[0,1] = torch.tensor((1,1,2,0.1,0.1,0,0.3,-0.2))\n",
    "artificial_labels[0,2] = torch.tensor((1,1,5,0.1,0.1,1,0.3,-0.2))\n",
    "artificial_labels[1,0] = torch.tensor((1,1,3,0.1,0.1,0,0.3,-0.2))\n",
    "\n",
    "artificial_netout = torch.zeros(size=(3,10,19), dtype=cv.netout_dtype)\n",
    "artificial_netout[0,1] = torch.tensor((1,1,0,0,10,0,0,0,0.1,0.1,10,0,0,0.3,-0.2,0,0,0,0))\n",
    "artificial_netout[0,2] = torch.tensor((1,1,0,0,0,0,0,10,0.1,0.1,0,10,0,0,0,0.3,-0.2,0,0))\n",
    "artificial_netout[1,0] = torch.tensor((1,1,0,0,0,10,0,0,0.1,0.1,10,0,0,0.3,-0.2,0,0,0,0))\n",
    "\n",
    "print(my_loss(artificial_netout, artificial_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
